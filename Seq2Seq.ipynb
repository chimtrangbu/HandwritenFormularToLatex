{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xFGRQWr6jB10"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Jel8LfgijB2M"
   },
   "outputs": [],
   "source": [
    "xo = np.load(\"iseq_n.npy\")\n",
    "yo = np.load(\"oseq_n.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ALRBRrGIJOKa"
   },
   "outputs": [],
   "source": [
    "x = xo[:,:26,:]\n",
    "y = yo[:,:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1532261389351,
     "user": {
      "displayName": "Ole Kröger",
      "photoUrl": "//lh5.googleusercontent.com/-ciOdkP2qYNQ/AAAAAAAAAAI/AAAAAAAABxw/lDVb2_X04Yw/s50-c-k-no/photo.jpg",
      "userId": "108059461262407262819"
     },
     "user_tz": -120
    },
    "id": "fQBQQL3ol68m",
    "outputId": "aa7d3279-8ba4-4120-e845-0344dbad68ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "#ltokens:  28\n"
     ]
    }
   ],
   "source": [
    "nxchars = x.shape[2]\n",
    "print(nxchars)\n",
    "ltokens = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '+', '=', '#leq', '#neq', '#geq', '#alpha',\n",
    "                            '#beta', '#lambda', '#lt', '#gt', 'x', 'y', '^', '#frac', '{', '}' ,' ']\n",
    "print(\"#ltokens: \", len(ltokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fmU4uwY7jB2S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 25\n"
     ]
    }
   ],
   "source": [
    "x_seq_length = len(x[0])\n",
    "y_seq_length = len(y[0])- 1\n",
    "print(x_seq_length, y_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DC02d5lwjB2X"
   },
   "outputs": [],
   "source": [
    "def batch_data(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "#     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    while start + batch_size <= len(x):\n",
    "        yield x[start:start+batch_size], y[start:start+batch_size]\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T1Hfp3ojjB2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-fa3006c2938d>:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "nodes = 256\n",
    "embed_size = 20\n",
    "\n",
    "# Tensor where we will feed the data into graph\n",
    "inputs = tf.placeholder(tf.float32, (None, x_seq_length, nxchars), 'inputs')\n",
    "outputs = tf.placeholder(tf.int32, (None, None), 'output')\n",
    "targets = tf.placeholder(tf.int32, (None, None), 'targets')\n",
    "\n",
    "# Embedding layers\n",
    "output_embedding = tf.Variable(tf.random_uniform((len(ltokens)+1, embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)\n",
    "\n",
    "with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "    lstm_enc = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=inputs, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    lstm_dec = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)\n",
    "#connect outputs to \n",
    "logits = tf.contrib.layers.fully_connected(dec_outputs, num_outputs=len(ltokens)+1, activation_fn=None) \n",
    "with tf.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43-L1cRKjB2u"
   },
   "source": [
    "Train the graph above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1532261396749,
     "user": {
      "displayName": "Ole Kröger",
      "photoUrl": "//lh5.googleusercontent.com/-ciOdkP2qYNQ/AAAAAAAAAAI/AAAAAAAABxw/lDVb2_X04Yw/s50-c-k-no/photo.jpg",
      "userId": "108059461262407262819"
     },
     "user_tz": -120
    },
    "id": "qTnfrvy3jB2x",
    "outputId": "ab001b54-7b62-4ddf-bdf9-d60951b768ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28  6  3 17 23  3 10  6  1  5 27 15 27 10  5  9  9 27 27 27 27 27 27 27\n",
      " 27 27]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=36)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1IaI_AYpzv2B"
   },
   "outputs": [],
   "source": [
    "def save(sess):\n",
    "    saver = tf.train.Saver(None)\n",
    "\n",
    "    save_path = saver.save(sess, save_path=\"seq_mod/model\", global_step=None)\n",
    "    print('model saved at %s' % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore(sess):\n",
    "    saver = tf.train.Saver(None)\n",
    "    path = \"seq_mod/model\"\n",
    "    saver.restore(sess, save_path=path)\n",
    "    print('model restored from %s' % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39124,
     "status": "ok",
     "timestamp": 1532261160700,
     "user": {
      "displayName": "Ole Kröger",
      "photoUrl": "//lh5.googleusercontent.com/-ciOdkP2qYNQ/AAAAAAAAAAI/AAAAAAAABxw/lDVb2_X04Yw/s50-c-k-no/photo.jpg",
      "userId": "108059461262407262819"
     },
     "user_tz": -120
    },
    "id": "gz89pWSJjB20",
    "outputId": "3cd1d6e9-9761-4848-b4d9-a4f8404d1704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from seq_mod/model\n",
      "model restored from seq_mod/model\n",
      "Epoch   0 Loss:  0.181 Accuracy: 0.9363 Epoch duration: 26.194s\n",
      "Accuracy on test set is:  0.640\n",
      "model saved at seq_mod/model\n",
      "Epoch   1 Loss:  0.173 Accuracy: 0.9424 Epoch duration: 24.854s\n",
      "Accuracy on test set is:  0.631\n",
      "Epoch   2 Loss:  0.188 Accuracy: 0.9348 Epoch duration: 25.391s\n",
      "Accuracy on test set is:  0.638\n",
      "Epoch   3 Loss:  0.174 Accuracy: 0.9398 Epoch duration: 25.858s\n",
      "Accuracy on test set is:  0.639\n",
      "Epoch   4 Loss:  0.133 Accuracy: 0.9548 Epoch duration: 26.276s\n",
      "Accuracy on test set is:  0.627\n",
      "Epoch   5 Loss:  0.128 Accuracy: 0.9595 Epoch duration: 24.788s\n",
      "Accuracy on test set is:  0.635\n",
      "model saved at seq_mod/model\n",
      "Epoch   6 Loss:  0.229 Accuracy: 0.9208 Epoch duration: 27.643s\n",
      "Accuracy on test set is:  0.635\n",
      "Epoch   7 Loss:  0.142 Accuracy: 0.9537 Epoch duration: 24.047s\n",
      "Accuracy on test set is:  0.644\n",
      "Epoch   8 Loss:  0.142 Accuracy: 0.9509 Epoch duration: 23.995s\n",
      "Accuracy on test set is:  0.643\n",
      "Epoch   9 Loss:  0.152 Accuracy: 0.9473 Epoch duration: 23.971s\n",
      "Accuracy on test set is:  0.634\n",
      "Epoch  10 Loss:  0.110 Accuracy: 0.9654 Epoch duration: 24.038s\n",
      "Accuracy on test set is:  0.642\n",
      "model saved at seq_mod/model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    restore(sess)\n",
    "    epochs = 1000\n",
    "    for epoch_i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "            _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "                feed_dict = {inputs: source_batch,\n",
    "                 outputs: target_batch[:, :-1],\n",
    "                 targets: target_batch[:, 1:]})\n",
    "\n",
    "        accuracy = np.mean(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "        print('Epoch {:3} Loss: {:>6.3f} Accuracy: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, \n",
    "                                                                          accuracy, time.time() - start_time))\n",
    "\n",
    "        source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "        dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "        for i in range(y_seq_length):\n",
    "            batch_logits = sess.run(logits,\n",
    "                        feed_dict = {inputs: source_batch,\n",
    "                         outputs: dec_input})\n",
    "            prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "            dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "        print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))     \n",
    "        if epoch_i % 5 == 0:\n",
    "            save(sess)\n",
    "    \n",
    "    save(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8PTFAcXjB29"
   },
   "source": [
    "Translate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from seq_mod/model\n",
      "model restored from seq_mod/model\n",
      "Accuracy on test set is:  0.632\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    restore(sess)\n",
    "    batch_size = 512\n",
    "    source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "    dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "    for i in range(y_seq_length):\n",
    "        batch_logits = sess.run(logits,\n",
    "                    feed_dict = {inputs: source_batch,\n",
    "                     outputs: dec_input})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPFJMJoyjB3B"
   },
   "source": [
    "Let's randomly take two from this test set and see what it spits out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.  7.  8.  3. 11.  3.  5. 27. 12. 27.  8.  1.  3. 27. 27. 27. 27. 27.\n",
      " 27. 27. 27. 27. 27. 27. 27. 27.]\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '+', '=', '#leq', '#neq', '#geq', '#alpha', '#beta', '#lambda', '#lt', '#gt', 'x', 'y', '^', '#frac', '{', '}', ' ']\n",
      "result: 783+35 = 813             \n",
      "Correct: 287+56 = 343             \n"
     ]
    }
   ],
   "source": [
    "# i = random.randint(0, 511)\n",
    "print(dec_input[i,:])\n",
    "print(ltokens)\n",
    "seq = \"\"\n",
    "for c in dec_input[i,1:]:\n",
    "    c = int(c)\n",
    "    if c != 28:\n",
    "        seq += ltokens[c] \n",
    "        \n",
    "print(\"result:\", seq)\n",
    "\n",
    "seq = \"\"\n",
    "for c in target_batch[i,1:]:\n",
    "    c = int(c)\n",
    "    \n",
    "    if c != 28:\n",
    "        seq += ltokens[c] \n",
    "\n",
    "print(\"Correct:\", seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    restore(sess)\n",
    "    batch_size = 512\n",
    "    source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "    dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "    for i in range(y_seq_length):\n",
    "        batch_logits = sess.run(logits,\n",
    "                    feed_dict = {inputs: source_batch,\n",
    "                     outputs: dec_input})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))\n",
    "    cc = 0\n",
    "    fcc = 0\n",
    "    fc = 0\n",
    "    fl = 0\n",
    "    nl = 0\n",
    "    for i in range(len(dec_input)):\n",
    "        feq = False\n",
    "        pseq = \"\"\n",
    "        for c in dec_input[i,1:]:\n",
    "            c = int(c)\n",
    "            if c != 28:\n",
    "                pseq += ltokens[c] \n",
    "\n",
    "        cseq = \"\"\n",
    "        cseql = \"\"\n",
    "        for c in target_batch[i,1:]:\n",
    "            c = int(c)\n",
    "\n",
    "            if c != 28:\n",
    "                cseq += ltokens[c] \n",
    "                cseql += ltokens[c][0]\n",
    "                if ltokens[c] == \"#frac\":\n",
    "                    fc += 1\n",
    "                    feq = True\n",
    "\n",
    "        if pseq == cseq:\n",
    "            cc += 1\n",
    "            if feq:\n",
    "                fcc += 1\n",
    "        cseql = cseql.rstrip()\n",
    "        if feq:\n",
    "            fl += len(cseql)\n",
    "        else:\n",
    "            nl += len(cseql)\n",
    "        \n",
    "    print(\"Accuracy %.2f %%\" % (cc/len(dec_input)*100))  \n",
    "    print(\"Accuracy for fraction equations %.2f %%\" % (fcc/fc*100))\n",
    "    print(\"Accuracy for simple equations %.2f %%\" % ((cc-fcc)/(len(dec_input)-fc)*100))\n",
    "    print(\"Average length frac: %.1f\" % (fl/fc))\n",
    "    print(\"Average length simple: %.1f\" % (nl/(len(dec_input)-fc)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Seq2Seq.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
